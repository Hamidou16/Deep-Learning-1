{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Self Organizing Maps\n",
    "In this section we will: \n",
    "<ol>\n",
    "    <li> build a Self Organizing Map (SOM) </li>\n",
    "    <li> return the specific features(like frauds) detected by the SOM </li>\n",
    "    <li> make a Hybrid Deep Learning model </li>\n",
    "</ol>\n",
    "We will do an unsupervised deep learning to detect frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  \\\n",
      "0    15776156   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2   \n",
      "1    15739548   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2   \n",
      "2    15662854   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2   \n",
      "3    15687688   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2   \n",
      "4    15715750   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   \n",
      "\n",
      "   A13   A14  Class  \n",
      "0  100  1213      0  \n",
      "1  160     1      0  \n",
      "2  280     1      0  \n",
      "3    0     1      1  \n",
      "4   60   159      1  \n",
      "(690, 16)\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Credit_Card_Applications.csv')\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset concerns credit card applications. All attribute names have been changed to meaningless symbols to protect confidentiality of the data.\n",
    "<br> The dataset is interesting because there is a good mix of attributes; continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15776156.           1.          22.08        11.46         2.           4.\n",
      "          4.           1.58         0.           0.           0.           1.\n",
      "          2.         100.        1213.  ]\n",
      " [ 15739548.           0.          22.67         7.           2.           8.\n",
      "          4.           0.17         0.           0.           0.           0.\n",
      "          2.         160.           1.  ]]\n",
      "[0 0 0 1 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Creating 2 datasets\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(X[0:2, :])\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84  1.    0.13  0.41  0.5   0.23  0.38  0.06  0.    0.    0.    1.\n",
      "   0.5   0.05  0.01]\n",
      " [ 0.7   0.    0.13  0.25  0.5   0.54  0.38  0.01  0.    0.    0.    0.\n",
      "   0.5   0.08  0.  ]\n",
      " [ 0.39  0.    0.24  0.06  0.    0.23  0.38  0.04  0.    0.    0.    1.\n",
      "   0.5   0.14  0.  ]\n",
      " [ 0.49  0.    0.12  0.41  0.    0.31  0.25  0.    1.    1.    0.16  1.\n",
      "   0.5   0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X = sc.fit_transform(X)\n",
    "print(X[0:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SOM\n",
    "from minisom import MiniSom # Importing the MiniSom class which is present in the minisom.py file\n",
    "som = MiniSom(x=10, y=10, input_len=15, sigma=1.0, learning_rate=0.5) # Creating our object\n",
    "som.random_weights_init(X) # Initializing our weights using the random_weights_init function\n",
    "som.train_random(X, num_iteration=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xade67b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the results\n",
    "from pylab import bone, pcolor, colorbar, plot, show\n",
    "bone()\n",
    "pcolor(som.distance_map().T)\n",
    "colorbar()\n",
    "markers = ['o', 's']\n",
    "colors = ['r', 'g']\n",
    "# Looping through all customers\n",
    "for i, x in enumerate(X):\n",
    "    w = som.winner(x) # using the winner method in minisom.py file \n",
    "    plot(w[0]+0.5,\n",
    "         w[1]+0.5, # putting the marker in the middle of the node\n",
    "         markers[y[i]],\n",
    "         markeredgecolor=colors[y[i]],\n",
    "         markerfacecolor='None',\n",
    "         markersize=10,\n",
    "         markeredgewidth=2)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the lighter the wining node color is, the higher the Mean Interneuron Distance(MID) is, and inversely. \n",
    "<br> The green square means that the customer got an approval and the red circle means that the customer did not get. </br>\n",
    "<br> We can at least clearly notice that we have 2 outliers with coordinates (8,8) and (7,7).</br>\n",
    "<br> What is interesting is the association of the green square and the red circle.</br>\n",
    "<br> We will find out some potential frauds among the customers. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15638610.           0.          55.75         7.08         2.           4.\n",
      "          8.           6.75         1.           1.           3.           1.\n",
      "          2.         100.          51.  ]\n",
      " [ 15738487.           0.          20.75        10.25         2.          11.\n",
      "          4.           0.71         1.           1.           2.           1.\n",
      "          2.          49.           1.  ]\n",
      " [ 15773421.           0.          20.75        10.34         2.          13.\n",
      "          8.           0.34         1.           1.           1.           1.\n",
      "          2.          80.          51.  ]\n",
      " [ 15682686.           0.          31.25         3.75         2.          13.\n",
      "          8.           0.62         1.           1.           9.           1.\n",
      "          2.         181.           1.  ]\n",
      " [ 15781875.           0.          24.75        12.5          2.           6.\n",
      "          4.           1.5          1.           1.          12.           1.\n",
      "          2.         120.         568.  ]\n",
      " [ 15761554.           0.          30.5          6.5          2.           8.\n",
      "          5.           4.           1.           1.           7.           1.\n",
      "          2.           0.        3066.  ]\n",
      " [ 15707602.           0.          22.83         2.29         2.          11.\n",
      "          8.           2.29         1.           1.           7.           1.\n",
      "          2.         140.        2385.  ]\n",
      " [ 15815095.           0.          22.58        10.75         2.          11.\n",
      "          4.           0.41         1.           1.           5.           1.\n",
      "          2.           0.         561.  ]\n",
      " [ 15720725.           0.          23.42         0.79         1.          11.\n",
      "          4.           1.5          1.           1.           2.           1.\n",
      "          2.          80.         401.  ]\n",
      " [ 15598614.           0.          23.          11.75         2.          14.\n",
      "          8.           0.5          1.           1.           2.           1.\n",
      "          2.         300.         552.  ]\n",
      " [ 15712483.           0.          46.67         0.46         2.          13.\n",
      "          8.           0.41         1.           1.          11.           1.\n",
      "          2.         440.           7.  ]\n",
      " [ 15572361.           0.          41.           2.04         1.          11.\n",
      "          8.           0.12         1.           1.          23.           1.\n",
      "          2.         455.        1237.  ]\n",
      " [ 15698522.           0.          19.75         0.75         2.           8.\n",
      "          4.           0.8          1.           1.           5.           1.\n",
      "          2.         140.           6.  ]\n",
      " [ 15660390.           0.          58.67         4.46         2.          11.\n",
      "          8.           3.04         1.           1.           6.           0.\n",
      "          2.          43.         561.  ]\n",
      " [ 15790254.           0.          18.92         9.           2.           6.\n",
      "          4.           0.75         1.           1.           2.           0.\n",
      "          2.          88.         592.  ]\n",
      " [ 15768600.           0.          22.42         5.67         2.          11.\n",
      "          4.           2.58         1.           1.           7.           0.\n",
      "          2.         129.        3258.  ]\n",
      " [ 15748552.           0.          30.67        12.           2.           8.\n",
      "          4.           2.           1.           1.           1.           0.\n",
      "          2.         220.          20.  ]\n",
      " [ 15757467.           0.          52.83        15.           2.           8.\n",
      "          4.           5.5          1.           1.          14.           0.\n",
      "          2.           0.        2201.  ]\n",
      " [ 15766183.           0.          24.5          0.5          2.          11.\n",
      "          8.           1.5          1.           0.           0.           0.\n",
      "          2.         280.         825.  ]\n",
      " [ 15682576.           0.          32.17         1.46         2.           9.\n",
      "          4.           1.08         1.           1.          16.           0.\n",
      "          2.         120.        2080.  ]\n",
      " [ 15642391.           0.          20.42         0.83         2.          11.\n",
      "          4.           1.58         1.           1.           1.           0.\n",
      "          2.           0.           1.  ]\n",
      " [ 15801441.           0.          35.75         0.91         2.           6.\n",
      "          4.           0.75         1.           1.           4.           0.\n",
      "          2.           0.        1584.  ]\n",
      " [ 15815443.           0.          57.08        19.5          2.           8.\n",
      "          4.           5.5          1.           1.           7.           0.\n",
      "          2.           0.        3001.  ]\n",
      " [ 15748432.           0.          58.33        10.           2.          11.\n",
      "          4.           4.           1.           1.          14.           0.\n",
      "          2.           0.        1603.  ]\n",
      " [ 15708714.           0.          18.75         7.5          2.          11.\n",
      "          4.           2.71         1.           1.           5.           0.\n",
      "          2.         184.       26727.  ]\n",
      " [ 15705343.           0.          20.33        10.           2.           8.\n",
      "          8.           1.           1.           1.           4.           0.\n",
      "          2.          50.        1466.  ]\n",
      " [ 15657778.           0.          24.75         3.           2.          11.\n",
      "          8.           1.83         1.           1.          19.           0.\n",
      "          2.           0.         501.  ]\n",
      " [ 15788131.           0.          29.5          0.46         2.           4.\n",
      "          4.           0.54         1.           1.           4.           0.\n",
      "          2.         380.         501.  ]\n",
      " [ 15652658.           0.          33.08         4.62         2.          11.\n",
      "          8.           1.62         1.           1.           2.           0.\n",
      "          2.           0.           1.  ]\n",
      " [ 15635244.           0.          20.67         3.           2.          11.\n",
      "          4.           0.17         1.           1.           3.           0.\n",
      "          2.         100.           7.  ]\n",
      " [ 15624595.           0.          22.42        11.25         1.          14.\n",
      "          8.           0.75         1.           1.           4.           0.\n",
      "          2.           0.         322.  ]\n",
      " [ 15772329.           0.          28.08        15.           1.          10.\n",
      "          9.           0.           1.           0.           0.           0.\n",
      "          2.           0.       13213.  ]\n",
      " [ 15734649.           0.          40.83        10.           2.          11.\n",
      "          8.           1.75         1.           0.           0.           0.\n",
      "          2.          29.         838.  ]\n",
      " [ 15688264.           0.          19.67         0.21         2.          11.\n",
      "          8.           0.29         1.           1.          11.           0.\n",
      "          2.          80.         100.  ]\n",
      " [ 15771856.           0.          24.5         12.75         2.           8.\n",
      "          5.           4.75         1.           1.           2.           0.\n",
      "          2.          73.         445.  ]\n",
      " [ 15679394.           0.          36.           1.           2.           8.\n",
      "          4.           2.           1.           1.          11.           0.\n",
      "          2.           0.         457.  ]\n",
      " [ 15646082.           0.          18.83         4.42         1.           8.\n",
      "          8.           3.           1.           0.           0.           0.\n",
      "          2.         240.           1.  ]\n",
      " [ 15720644.           0.          40.33         7.54         1.          11.\n",
      "          8.           8.           1.           1.          14.           0.\n",
      "          2.           0.        2301.  ]\n",
      " [ 15717629.           0.          25.17         2.88         2.          14.\n",
      "          8.           0.88         1.           0.           0.           0.\n",
      "          2.         360.           1.  ]\n",
      " [ 15808023.           0.          28.17         0.38         2.          11.\n",
      "          4.           0.58         1.           1.           4.           0.\n",
      "          2.          80.           1.  ]\n",
      " [ 15795079.           0.          19.17         8.59         2.          13.\n",
      "          8.           0.75         1.           1.           7.           0.\n",
      "          2.          96.           1.  ]\n",
      " [ 15808386.           0.          22.5          8.5          2.          11.\n",
      "          4.           1.75         1.           1.          10.           0.\n",
      "          2.          80.         991.  ]\n",
      " [ 15746258.           0.          24.08         0.5          2.          11.\n",
      "          8.           1.25         1.           1.           1.           0.\n",
      "          2.           0.         679.  ]\n",
      " [ 15644878.           0.          47.25         0.75         2.          11.\n",
      "          8.           2.75         1.           1.           1.           0.\n",
      "          2.         333.         893.  ]\n",
      " [ 15671987.           0.          25.          12.33         2.          13.\n",
      "          8.           3.5          1.           1.           6.           0.\n",
      "          2.         400.         459.  ]\n",
      " [ 15776545.           0.          25.          11.           1.           6.\n",
      "          4.           4.5          1.           0.           0.           0.\n",
      "          2.         120.           1.  ]\n",
      " [ 15764841.           0.          20.42         7.5          2.           4.\n",
      "          4.           1.5          1.           1.           1.           0.\n",
      "          2.         160.         235.  ]\n",
      " [ 15748649.           0.          21.25         2.33         2.           3.\n",
      "          5.           0.5          1.           1.           4.           0.\n",
      "          1.          80.           1.  ]\n",
      " [ 15729718.           0.          21.5          6.           2.           6.\n",
      "          4.           2.5          1.           1.           3.           0.\n",
      "          2.          80.         919.  ]\n",
      " [ 15786539.           0.          20.67         1.83         2.          11.\n",
      "          4.           2.08         1.           1.           5.           0.\n",
      "          2.         220.        2504.  ]\n",
      " [ 15773776.           0.          35.42        12.           2.          11.\n",
      "          8.          14.           1.           1.           8.           0.\n",
      "          2.           0.        6591.  ]\n",
      " [ 15778345.           0.          17.83        11.           2.          14.\n",
      "          8.           1.           1.           1.          11.           0.\n",
      "          2.           0.        3001.  ]\n",
      " [ 15700511.           0.          28.5          3.04         1.          14.\n",
      "          8.           2.54         1.           1.           1.           0.\n",
      "          2.          70.           1.  ]\n",
      " [ 15791769.           0.          26.92        13.5          2.          11.\n",
      "          8.           5.           1.           1.           2.           0.\n",
      "          2.           0.        5001.  ]\n",
      " [ 15793896.           0.          28.42         3.5          2.           9.\n",
      "          4.           0.83         1.           0.           0.           0.\n",
      "          1.         280.           1.  ]\n",
      " [ 15776494.           0.          27.42        14.5          2.          14.\n",
      "          8.           3.08         1.           1.           1.           0.\n",
      "          2.         120.          12.  ]]\n",
      "(56, 15)\n"
     ]
    }
   ],
   "source": [
    "# Finding the frauds\n",
    "mappings = som.win_map(X) # Getting all the mappings of the winning nodes of our self organizing map\n",
    "                          # Again, the win method is in minisom.py\n",
    "# print(mappings)\n",
    "frauds = np.concatenate((mappings[(8,8)], mappings[(7,7)]), axis=0)\n",
    "frauds = sc.inverse_transform(frauds)\n",
    "print(frauds)\n",
    "print(frauds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the customers information with potential frauds, and specially their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.]\n",
      "(690,)\n",
      "(690, 15)\n"
     ]
    }
   ],
   "source": [
    "# Make a hybrid Deep Learning Model\n",
    "# Combine the SOM results and a Supervised Deep Learning (ANN)\n",
    "\n",
    "# Creating the matrix of features\n",
    "customers = dataset.iloc[:, 1:].values\n",
    "# Creating the dependent variable\n",
    "is_fraud = np.zeros(len(dataset)) # Initializing our dependent vector\n",
    "\n",
    "# Extracting the customers that are in the frauds list from the data dataset\n",
    "for i in range(len(dataset)):\n",
    "    if dataset.iloc[i,0] in frauds:  # if the customer with ID i is in frauds\n",
    "        is_fraud[i] = 1              # 1 correspond to fraud\n",
    "# print(is_fraud)\n",
    "print(is_fraud[0:200])\n",
    "print(is_fraud.shape)\n",
    "print(customers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "690/690 [==============================] - 3s 5ms/step - loss: 0.4742 - acc: 0.9188\n",
      "Epoch 2/2\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.2142 - acc: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xded8a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to use the ANN\n",
    "\n",
    "# Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "customers = sc.fit_transform(customers)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Importing the libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\", input_dim=15))\n",
    "\n",
    "# Adding the final layer (the output layer)\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fitting our ANN to the training set\n",
    "classifier.fit(customers, is_fraud, batch_size=1, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15776156.   ,         0.012],\n",
       "       [ 15739548.   ,         0.053],\n",
       "       [ 15662854.   ,         0.023],\n",
       "       ..., \n",
       "       [ 15675450.   ,         0.222],\n",
       "       [ 15776494.   ,         0.355],\n",
       "       [ 15592412.   ,         0.099]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the probabilities of frauds  \n",
    "y_pred = classifier.predict(customers)\n",
    "y_pred = np.concatenate((dataset.iloc[:, 0:1].values, y_pred), axis=1)\n",
    "np.set_printoptions(precision=3)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 2)\n",
      "[[ 15643056.            0.003]\n",
      " [ 15778589.            0.004]\n",
      " [ 15787229.            0.004]\n",
      " [ 15676156.            0.005]\n",
      " [ 15644400.            0.005]\n",
      " [ 15709252.            0.005]\n",
      " [ 15600975.            0.005]\n",
      " [ 15679622.            0.005]\n",
      " [ 15701885.            0.005]\n",
      " [ 15625311.            0.005]\n",
      " [ 15569917.            0.005]\n",
      " [ 15655658.            0.006]\n",
      " [ 15604196.            0.006]\n",
      " [ 15758477.            0.006]\n",
      " [ 15673747.            0.006]\n",
      " [ 15604130.            0.006]\n",
      " [ 15670646.            0.006]\n",
      " [ 15686670.            0.006]\n",
      " [ 15567860.            0.006]\n",
      " [ 15684440.            0.007]]\n"
     ]
    }
   ],
   "source": [
    "# Sorting these customers by their probabilities of doing frauds\n",
    "y_pred = y_pred[y_pred[:, 1].argsort()]\n",
    "print(y_pred.shape)\n",
    "print(y_pred[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted probabilities are ranked from the lowest to the highest, as we can see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will:\n",
    "<br> Build a Boltzmann machine.</br>\n",
    "<br> Boltzmann Machines can be seen from 2 different points of view :</br>\n",
    "<ul>\n",
    "    <li> An Energy-Based Model (EBM)</li>\n",
    "    <li> A Probabilistic Graphical Model (PGM) </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn # module of torch to implement neural networks\n",
    "import torch.nn.parallel # for parallel computing\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable # for Stochastic Gradient Desccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3883, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy\n",
       "5        6                         Heat (1995)         Action|Crime|Thriller\n",
       "6        7                      Sabrina (1995)                Comedy|Romance\n",
       "7        8                 Tom and Huck (1995)          Adventure|Children's\n",
       "8        9                 Sudden Death (1995)                        Action\n",
       "9       10                    GoldenEye (1995)     Action|Adventure|Thriller"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "# Movies dataset\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1', \n",
    "                     names=['MovieID', 'Title','Genres'])\n",
    "print(movies.shape)\n",
    "movies.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>06810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>11413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>61614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>95370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  Occupation    Zip\n",
       "0       1      F    1          10  48067\n",
       "1       2      M   56          16  70072\n",
       "2       3      M   25          15  55117\n",
       "3       4      M   45           7  02460\n",
       "4       5      M   25          20  55455\n",
       "5       6      F   50           9  55117\n",
       "6       7      M   35           1  06810\n",
       "7       8      M   25          12  11413\n",
       "8       9      M   25          17  61614\n",
       "9      10      F   35           1  95370"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users dataset\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1',\n",
    "                   names=['UserID','Gender','Age','Occupation','Zip'])\n",
    "print(users.shape)\n",
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291\n",
       "5       1     1197       3  978302268\n",
       "6       1     1287       5  978302039\n",
       "7       1     2804       5  978300719\n",
       "8       1      594       4  978302268\n",
       "9       1      919       4  978301368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings dataset\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1',\n",
    "                     names=['UserID','MovieID','Rating','Timestamp'])\n",
    "print(ratings.shape)\n",
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1997-09-23 07:02:38'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "%time\n",
    "ratings['Time']=ratings['Timestamp'].apply(datetime.fromtimestamp)\n",
    "datetime.fromtimestamp(int(\"874965758\")).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>875072484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>878543541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>875072262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>875071805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1        1       5  874965758\n",
       "1       1        2       3  876893171\n",
       "2       1        3       4  878542960\n",
       "3       1        4       3  876893119\n",
       "4       1        5       3  889751712\n",
       "5       1        7       4  875071561\n",
       "6       1        8       1  875072484\n",
       "7       1        9       5  878543541\n",
       "8       1       11       2  875072262\n",
       "9       1       13       5  875071805"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the training set\n",
    "# We made 5 slipts of our ml-100k('base' means training set and 'test' means test set)\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t', names=['UserID','MovieID','Rating','Timestamp'])\n",
    "print(training_set.shape)\n",
    "training_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole dataset in ml-100k is 100,000 ratings and since each observation corresponds to 1 rating, so we the splitting of 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         1,         5, 874965758],\n",
       "       [        1,         2,         3, 876893171]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the training_set into a nympy array \n",
    "t_df=training_set.copy()\n",
    "training_set = np.array(training_set, dtype='int')\n",
    "training_set[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>887431973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>875073198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1        6       5  887431973\n",
       "1       1       10       3  875693118\n",
       "2       1       12       5  878542960\n",
       "3       1       14       5  874965706\n",
       "4       1       17       3  875073198"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing and converting the test set into a numpy array\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t', names=['UserID','MovieID','Rating','Timestamp'])\n",
    "print(test_set.shape)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         6,         5, 887431973],\n",
       "       [        1,        10,         3, 875693118]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df=test_set.copy()\n",
    "test_set = np.array(test_set, dtype='int')\n",
    "test_set[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "# Getting the number of users and movies\n",
    "# Going to convert our matrix where the lines are going to be the users\n",
    "# The columns are going to be the movies\n",
    "# And the sales are going to be the ratings\n",
    "\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
    "print(nb_users)\n",
    "print(nb_movies)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "1591\n",
      "943\n",
      "462\n"
     ]
    }
   ],
   "source": [
    "# let us just check\n",
    "print(max(training_set[:, 1]))\n",
    "print(max(test_set[:, 1]))\n",
    "print(max(training_set[:, 0]))\n",
    "print(max(test_set[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum of nb_movies and nb_users were in the training_set, but they could have been in the test_set also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into an array with users in lines and movies in columns (943x1682)\n",
    "# We need to make a specific structure of data of what the Restricted Boltzmann expects, a list of a list\n",
    "# Creating a function to apply it to the traning set and the test set\n",
    "# We need to map all the users with the movies, if there is no movie rated by a user, it is taken as zero\n",
    "\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users] # Taking all the MovieID of the 1st user, because id_users starts at 1\n",
    "        id_ratings = data[:,2][data[:,0] == id_users] # Taking all the ratings of the 1st user\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 551 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.DataFrame(training_set).shape)\n",
    "len(training_set), len(training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1672  \\\n",
       "0   5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...    0.0   \n",
       "1   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(training_set).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>943</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "      <td>875501756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserID  MovieID  Rating  Timestamp\n",
       "79995     943     1067       2  875501756\n",
       "79996     943     1074       4  888640250\n",
       "79997     943     1188       3  888640250\n",
       "79998     943     1228       3  888640275\n",
       "79999     943     1330       3  888692465"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = t_df.groupby('UserID').apply(lambda x: sorted(zip(list(x['MovieID']),list(x['Rating']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID\n",
       "1    [(1, 5), (2, 3), (3, 4), (4, 3), (5, 3), (7, 4...\n",
       "2    [(1, 4), (10, 2), (14, 4), (25, 4), (100, 5), ...\n",
       "3    [(181, 4), (258, 2), (260, 4), (268, 3), (271,...\n",
       "4    [(11, 4), (210, 3), (258, 5), (271, 4), (300, ...\n",
       "5    [(21, 3), (25, 3), (29, 4), (50, 4), (63, 1), ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.apply(lambda x: {i[0]:i[1] for i in x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID\n",
       "1    {1: 5, 2: 3, 3: 4, 4: 3, 5: 3, 7: 4, 8: 1, 9: ...\n",
       "2    {1: 4, 10: 2, 14: 4, 25: 4, 100: 5, 111: 4, 12...\n",
       "3    {181: 4, 258: 2, 260: 4, 268: 3, 271: 3, 288: ...\n",
       "4    {11: 4, 210: 3, 258: 5, 271: 4, 300: 5, 301: 5...\n",
       "5    {21: 3, 25: 3, 29: 4, 50: 4, 63: 1, 66: 1, 70:...\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   1673  \\\n",
       "0   5.0   3.0   4.0   3.0   3.0   NaN   4.0   1.0   5.0   NaN  ...    NaN   \n",
       "1   4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...    NaN   \n",
       "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    NaN   \n",
       "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    NaN   \n",
       "4   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    NaN   \n",
       "\n",
       "   1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1650 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp.tolist()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped = pd.DataFrame(tmp.tolist(),columns=range(1,nb_movies+1)).fillna(0)\n",
    "mapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...   1673  \\\n",
       "0   5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...    0.0   \n",
       "1   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mapped.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our training_set and our mapped list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array_equal(mapped.values, np.array(training_set))) # That's one way\n",
    "mapped.values.tolist()==training_set # Another way with the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataset into Torch Tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 5., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 0, 1,  ..., 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set==0 # All the zeros in the training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n",
    "training_set[training_set==0]=-1 # Means -1 will be no ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  3.,  4.,  ..., -1., -1., -1.],\n",
       "        [ 4., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [ 5., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1.,  5., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set==0]=-1 # No ratings\n",
    "training_set[training_set==1]=0 # No likes\n",
    "training_set[training_set==2]=0 # No likes\n",
    "training_set[training_set>=3]=1 # Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the test_set\n",
    "test_set[test_set==0]=-1\n",
    "test_set[test_set==1]=0\n",
    "test_set[test_set==2]=0\n",
    "test_set[test_set>=3]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0171, -0.6540,  1.7576, -0.0835],\n",
       "        [-0.8068, -2.0485,  0.7299, -0.3903]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Going deeper in Torch\n",
    "torch.randn(2,4) # random numbers from a normal distribution with mean 0 and variance 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3524, -0.0088, -0.4379, -0.3914, -1.3420, -0.8285,  0.4344]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0989, -0.7846, -1.4483, -1.0103],\n",
       "        [-0.1219,  1.0607, -1.1750, -1.4361]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 2, 3, 5],\n",
       "        [6, 2, 7, 9]], dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.IntTensor([[8,2,3,5],[6,2,7,9]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[66, 22, 11],\n",
       "        [77, 33, 99],\n",
       "        [ 5,  5, 11],\n",
       "        [13, 31,  2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.IntTensor([[66,22,11],[77,33,99],[5,5,11],[13,31,2]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[762, 412, 329],\n",
       "        [702, 512, 359]], dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x,y) # multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 2, 3, 5],\n",
       "        [6, 2, 7, 9]], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 6],\n",
       "        [2, 2],\n",
       "        [3, 7],\n",
       "        [5, 9]], dtype=torch.int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t() # Transposed of x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[102, 118],\n",
       "        [118, 170]], dtype=torch.int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x, x.t()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100,  28,  66,  94],\n",
       "        [ 28,   8,  20,  28],\n",
       "        [ 66,  20,  58,  78],\n",
       "        [ 94,  28,  78, 106]], dtype=torch.int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x.t(),x) # Transposition is not commutative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the architecture of the NN\n",
    "<ul>\n",
    "<li> W: weights, probabilities of visible nodes given the hidden nodes </li>\n",
    "<li> nv: No. of visible nodes </li>\n",
    "    <li> nh: No. of hidden nodes </li>\n",
    "    <li> a, b: bias </li>\n",
    "    <li> a: the probabilities of the hidden nodes given the visible nodes, p(h) given v </li>\n",
    "    <li> b: the probabilities of the visible nodes given the hidden nodes </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9991,  0.2125,  1.9158, -1.0880]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But first recall some basics in PyTorch\n",
    "\n",
    "q=torch.randn(1,4) # Randomly initialized matrix\n",
    "print(type(q))\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9991,  0.2125,  1.9158, -1.0880],\n",
       "        [ 0.9991,  0.2125,  1.9158, -1.0880],\n",
       "        [ 0.9991,  0.2125,  1.9158, -1.0880],\n",
       "        [ 0.9991,  0.2125,  1.9158, -1.0880],\n",
       "        [ 0.9991,  0.2125,  1.9158, -1.0880]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.expand_as(torch.rand(5,4)) # Pretty forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1138,  1.3386,  0.1511,  0.8549],\n",
       "        [-0.4586, -0.4285,  0.6680, -0.2793],\n",
       "        [-0.7813,  0.1676, -1.5403, -2.1250]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = torch.randn(3,4)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7528, 0.7923, 0.5377, 0.7016],\n",
       "        [0.3873, 0.3945, 0.6610, 0.4306],\n",
       "        [0.3140, 0.5418, 0.1765, 0.1067]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(aaa) # sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8490, 0.2341, 0.5122, 0.8622, 0.1586, 0.3497],\n",
       "        [0.7018, 0.8958, 0.1742, 0.6127, 0.4806, 0.7101]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=torch.rand(2,6)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1., 1., 1.],\n",
       "        [0., 1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.bernoulli?\n",
    "torch.bernoulli(aa) # Bernoulli function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3533, 0.7078, 0.3434, 0.7771],\n",
       "        [0.4020, 0.7933, 0.6139, 0.1412]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = torch.rand(2,4)\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1320)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(cc) # Sum of the elements of cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7552, 1.5011, 0.9574, 0.9183])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(cc, 0) # Sum of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1816, 1.9504])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(cc, 1) # Sum of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the NN\n",
    "\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv) # Initializing randomly according to a normal ditribution\n",
    "        self.a = torch.randn(1, nh) # 2D tensor, 1st dim corresponds to the batch and the 2nd to the bias\n",
    "        self.b = torch.randn(1, nv) \n",
    "        \n",
    "    # sampling the hidden nodes according to the probabilities p(h) given v\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx) \n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    # sampling the visible nodes according to the probabilities p(v) given h\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    # Using the contrastive divergence to estimate the log-likelihood divergence\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        string= \"RBM object\\nnv: {}\\nnh: {}\".format(nv, nh)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682 100\n"
     ]
    }
   ],
   "source": [
    "nv=len(training_set[0]) # nv = len(nb_movies) also works\n",
    "nh=100\n",
    "print(nv, nh)\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBM object\n",
       "nv: 1682\n",
       "nh: 100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a RBM object\n",
    "rbm = RBM(nv, nh)\n",
    "nb_epoch=12\n",
    "rbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.3079)\n",
      "epoch: 2 loss: tensor(0.1368)\n",
      "epoch: 3 loss: tensor(0.1408)\n",
      "epoch: 4 loss: tensor(0.1470)\n",
      "epoch: 5 loss: tensor(0.1477)\n",
      "epoch: 6 loss: tensor(0.1542)\n",
      "epoch: 7 loss: tensor(0.1449)\n",
      "epoch: 8 loss: tensor(0.1501)\n",
      "epoch: 9 loss: tensor(0.1472)\n",
      "epoch: 10 loss: tensor(0.1482)\n",
      "epoch: 11 loss: tensor(0.1469)\n",
      "epoch: 12 loss: tensor(0.1507)\n"
     ]
    }
   ],
   "source": [
    "# Training the RBM\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    \n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user + batch_size]\n",
    "        v0 = training_set[id_user:id_user + batch_size] # At the beginning the target is same as the input\n",
    "        ph0, _ = rbm.sample_h(v0) # Initial probabilities, probabilities of the hn = 1 given the real ratings\n",
    "        \n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk) # Get the 1st sampled hidden node (here vk=v0)\n",
    "            _, vk = rbm.sample_v(hk) # Update vk, visible node after the 1st sampling\n",
    "            vk[v0<0] = v0[v0<0] # Make sure that the non-rated movies are not trained\n",
    "            \n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>0] - vk[v0>0]))\n",
    "        s += 1.\n",
    "        \n",
    "    print('epoch: '+ str(epoch) + ' loss: '+ str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1.,  1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2329)\n"
     ]
    }
   ],
   "source": [
    "# Testing the RBM\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will:\n",
    "<ol>\n",
    "    <li> build an AutoEncoder from scratch with PyTorch </li>\n",
    "    <li> how to manipulate classes and objects to improve and tune your AutoEncoder </li>\n",
    "</ol>\n",
    "We will be using the same datasets as the ones in the Boltzmann Machines section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn # module of torch to implement neural networks\n",
    "import torch.nn.parallel # for parallel computing\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable # for Stochastic Gradient Desccent\n",
    "\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1', \n",
    "                     names=['MovieID', 'Title','Genres'])\n",
    "\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1',\n",
    "                   names=['UserID','Gender','Age','Occupation','Zip'])\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1',\n",
    "                     names=['UserID','MovieID','Rating','Timestamp'])\n",
    "\n",
    "# Training set and Test set\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t', names=['UserID','MovieID','Rating','Timestamp'])\n",
    "training_set = np.array(training_set, dtype='int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t', names=['UserID','MovieID','Rating','Timestamp'])\n",
    "test_set = np.array(test_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
    "\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users] # Taking all the MovieID of the 1st user, because id_users starts at 1\n",
    "        id_ratings = data[:,2][data[:,0] == id_users] # Taking all the ratings of the 1st user\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the NN\n",
    "class SAE(nn.Module): # Stacked Autoencoders\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)  \n",
    "        self.activation = nn.Sigmoid()      # Activation function\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x # vector of predicted ratings\n",
    "    \n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamidou\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(1.7716)\n",
      "epoch: 2 loss: tensor(1.0968)\n",
      "epoch: 3 loss: tensor(1.0533)\n",
      "epoch: 4 loss: tensor(1.0383)\n",
      "epoch: 5 loss: tensor(1.0308)\n",
      "epoch: 6 loss: tensor(1.0268)\n",
      "epoch: 7 loss: tensor(1.0238)\n",
      "epoch: 8 loss: tensor(1.0221)\n",
      "epoch: 9 loss: tensor(1.0208)\n",
      "epoch: 10 loss: tensor(1.0199)\n",
      "epoch: 11 loss: tensor(1.0188)\n",
      "epoch: 12 loss: tensor(1.0184)\n",
      "epoch: 13 loss: tensor(1.0183)\n",
      "epoch: 14 loss: tensor(1.0176)\n",
      "epoch: 15 loss: tensor(1.0173)\n",
      "epoch: 16 loss: tensor(1.0170)\n",
      "epoch: 17 loss: tensor(1.0168)\n",
      "epoch: 18 loss: tensor(1.0166)\n",
      "epoch: 19 loss: tensor(1.0163)\n",
      "epoch: 20 loss: tensor(1.0162)\n",
      "epoch: 21 loss: tensor(1.0163)\n",
      "epoch: 22 loss: tensor(1.0160)\n",
      "epoch: 23 loss: tensor(1.0160)\n",
      "epoch: 24 loss: tensor(1.0160)\n",
      "epoch: 25 loss: tensor(1.0156)\n",
      "epoch: 26 loss: tensor(1.0158)\n",
      "epoch: 27 loss: tensor(1.0154)\n",
      "epoch: 28 loss: tensor(1.0151)\n",
      "epoch: 29 loss: tensor(1.0135)\n",
      "epoch: 30 loss: tensor(1.0115)\n",
      "epoch: 31 loss: tensor(1.0089)\n",
      "epoch: 32 loss: tensor(1.0062)\n",
      "epoch: 33 loss: tensor(1.0062)\n",
      "epoch: 34 loss: tensor(1.0031)\n",
      "epoch: 35 loss: tensor(1.0026)\n",
      "epoch: 36 loss: tensor(0.9992)\n",
      "epoch: 37 loss: tensor(0.9972)\n",
      "epoch: 38 loss: tensor(0.9958)\n",
      "epoch: 39 loss: tensor(0.9945)\n",
      "epoch: 40 loss: tensor(0.9917)\n",
      "epoch: 41 loss: tensor(0.9892)\n",
      "epoch: 42 loss: tensor(0.9863)\n",
      "epoch: 43 loss: tensor(0.9829)\n",
      "epoch: 44 loss: tensor(0.9809)\n",
      "epoch: 45 loss: tensor(0.9799)\n",
      "epoch: 46 loss: tensor(0.9774)\n",
      "epoch: 47 loss: tensor(0.9777)\n",
      "epoch: 48 loss: tensor(0.9749)\n",
      "epoch: 49 loss: tensor(0.9715)\n",
      "epoch: 50 loss: tensor(0.9683)\n",
      "epoch: 51 loss: tensor(0.9711)\n",
      "epoch: 52 loss: tensor(0.9670)\n",
      "epoch: 53 loss: tensor(0.9657)\n",
      "epoch: 54 loss: tensor(0.9631)\n",
      "epoch: 55 loss: tensor(0.9633)\n",
      "epoch: 56 loss: tensor(0.9608)\n",
      "epoch: 57 loss: tensor(0.9589)\n",
      "epoch: 58 loss: tensor(0.9584)\n",
      "epoch: 59 loss: tensor(0.9576)\n",
      "epoch: 60 loss: tensor(0.9558)\n",
      "epoch: 61 loss: tensor(0.9546)\n",
      "epoch: 62 loss: tensor(0.9513)\n",
      "epoch: 63 loss: tensor(0.9517)\n",
      "epoch: 64 loss: tensor(0.9495)\n",
      "epoch: 65 loss: tensor(0.9494)\n",
      "epoch: 66 loss: tensor(0.9474)\n",
      "epoch: 67 loss: tensor(0.9474)\n",
      "epoch: 68 loss: tensor(0.9454)\n",
      "epoch: 69 loss: tensor(0.9461)\n",
      "epoch: 70 loss: tensor(0.9434)\n",
      "epoch: 71 loss: tensor(0.9447)\n",
      "epoch: 72 loss: tensor(0.9419)\n",
      "epoch: 73 loss: tensor(0.9432)\n",
      "epoch: 74 loss: tensor(0.9416)\n",
      "epoch: 75 loss: tensor(0.9421)\n",
      "epoch: 76 loss: tensor(0.9400)\n",
      "epoch: 77 loss: tensor(0.9406)\n",
      "epoch: 78 loss: tensor(0.9395)\n",
      "epoch: 79 loss: tensor(0.9397)\n",
      "epoch: 80 loss: tensor(0.9384)\n",
      "epoch: 81 loss: tensor(0.9390)\n",
      "epoch: 82 loss: tensor(0.9376)\n",
      "epoch: 83 loss: tensor(0.9380)\n",
      "epoch: 84 loss: tensor(0.9371)\n",
      "epoch: 85 loss: tensor(0.9370)\n",
      "epoch: 86 loss: tensor(0.9360)\n",
      "epoch: 87 loss: tensor(0.9362)\n",
      "epoch: 88 loss: tensor(0.9355)\n",
      "epoch: 89 loss: tensor(0.9352)\n",
      "epoch: 90 loss: tensor(0.9346)\n",
      "epoch: 91 loss: tensor(0.9344)\n",
      "epoch: 92 loss: tensor(0.9339)\n",
      "epoch: 93 loss: tensor(0.9339)\n",
      "epoch: 94 loss: tensor(0.9332)\n",
      "epoch: 95 loss: tensor(0.9334)\n",
      "epoch: 96 loss: tensor(0.9326)\n",
      "epoch: 97 loss: tensor(0.9325)\n",
      "epoch: 98 loss: tensor(0.9315)\n",
      "epoch: 99 loss: tensor(0.9314)\n",
      "epoch: 100 loss: tensor(0.9310)\n",
      "epoch: 101 loss: tensor(0.9312)\n",
      "epoch: 102 loss: tensor(0.9303)\n",
      "epoch: 103 loss: tensor(0.9302)\n",
      "epoch: 104 loss: tensor(0.9298)\n",
      "epoch: 105 loss: tensor(0.9297)\n",
      "epoch: 106 loss: tensor(0.9292)\n",
      "epoch: 107 loss: tensor(0.9293)\n",
      "epoch: 108 loss: tensor(0.9287)\n",
      "epoch: 109 loss: tensor(0.9287)\n",
      "epoch: 110 loss: tensor(0.9282)\n",
      "epoch: 111 loss: tensor(0.9281)\n",
      "epoch: 112 loss: tensor(0.9276)\n",
      "epoch: 113 loss: tensor(0.9275)\n",
      "epoch: 114 loss: tensor(0.9271)\n",
      "epoch: 115 loss: tensor(0.9267)\n",
      "epoch: 116 loss: tensor(0.9263)\n",
      "epoch: 117 loss: tensor(0.9264)\n",
      "epoch: 118 loss: tensor(0.9260)\n",
      "epoch: 119 loss: tensor(0.9259)\n",
      "epoch: 120 loss: tensor(0.9253)\n",
      "epoch: 121 loss: tensor(0.9251)\n",
      "epoch: 122 loss: tensor(0.9247)\n",
      "epoch: 123 loss: tensor(0.9245)\n",
      "epoch: 124 loss: tensor(0.9242)\n",
      "epoch: 125 loss: tensor(0.9239)\n",
      "epoch: 126 loss: tensor(0.9234)\n",
      "epoch: 127 loss: tensor(0.9235)\n",
      "epoch: 128 loss: tensor(0.9233)\n",
      "epoch: 129 loss: tensor(0.9232)\n",
      "epoch: 130 loss: tensor(0.9228)\n",
      "epoch: 131 loss: tensor(0.9226)\n",
      "epoch: 132 loss: tensor(0.9221)\n",
      "epoch: 133 loss: tensor(0.9219)\n",
      "epoch: 134 loss: tensor(0.9216)\n",
      "epoch: 135 loss: tensor(0.9215)\n",
      "epoch: 136 loss: tensor(0.9213)\n",
      "epoch: 137 loss: tensor(0.9210)\n",
      "epoch: 138 loss: tensor(0.9207)\n",
      "epoch: 139 loss: tensor(0.9205)\n",
      "epoch: 140 loss: tensor(0.9203)\n",
      "epoch: 141 loss: tensor(0.9204)\n",
      "epoch: 142 loss: tensor(0.9199)\n",
      "epoch: 143 loss: tensor(0.9199)\n",
      "epoch: 144 loss: tensor(0.9194)\n",
      "epoch: 145 loss: tensor(0.9192)\n",
      "epoch: 146 loss: tensor(0.9190)\n",
      "epoch: 147 loss: tensor(0.9189)\n",
      "epoch: 148 loss: tensor(0.9188)\n",
      "epoch: 149 loss: tensor(0.9186)\n",
      "epoch: 150 loss: tensor(0.9185)\n",
      "epoch: 151 loss: tensor(0.9181)\n",
      "epoch: 152 loss: tensor(0.9176)\n",
      "epoch: 153 loss: tensor(0.9177)\n",
      "epoch: 154 loss: tensor(0.9176)\n",
      "epoch: 155 loss: tensor(0.9177)\n",
      "epoch: 156 loss: tensor(0.9174)\n",
      "epoch: 157 loss: tensor(0.9171)\n",
      "epoch: 158 loss: tensor(0.9169)\n",
      "epoch: 159 loss: tensor(0.9169)\n",
      "epoch: 160 loss: tensor(0.9165)\n",
      "epoch: 161 loss: tensor(0.9166)\n",
      "epoch: 162 loss: tensor(0.9160)\n",
      "epoch: 163 loss: tensor(0.9162)\n",
      "epoch: 164 loss: tensor(0.9159)\n",
      "epoch: 165 loss: tensor(0.9160)\n",
      "epoch: 166 loss: tensor(0.9155)\n",
      "epoch: 167 loss: tensor(0.9156)\n",
      "epoch: 168 loss: tensor(0.9149)\n",
      "epoch: 169 loss: tensor(0.9151)\n",
      "epoch: 170 loss: tensor(0.9146)\n",
      "epoch: 171 loss: tensor(0.9150)\n",
      "epoch: 172 loss: tensor(0.9144)\n",
      "epoch: 173 loss: tensor(0.9163)\n",
      "epoch: 174 loss: tensor(0.9168)\n",
      "epoch: 175 loss: tensor(0.9179)\n",
      "epoch: 176 loss: tensor(0.9171)\n",
      "epoch: 177 loss: tensor(0.9169)\n",
      "epoch: 178 loss: tensor(0.9166)\n",
      "epoch: 179 loss: tensor(0.9161)\n",
      "epoch: 180 loss: tensor(0.9160)\n",
      "epoch: 181 loss: tensor(0.9158)\n",
      "epoch: 182 loss: tensor(0.9156)\n",
      "epoch: 183 loss: tensor(0.9156)\n",
      "epoch: 184 loss: tensor(0.9152)\n",
      "epoch: 185 loss: tensor(0.9149)\n",
      "epoch: 186 loss: tensor(0.9147)\n",
      "epoch: 187 loss: tensor(0.9146)\n",
      "epoch: 188 loss: tensor(0.9145)\n",
      "epoch: 189 loss: tensor(0.9142)\n",
      "epoch: 190 loss: tensor(0.9139)\n",
      "epoch: 191 loss: tensor(0.9139)\n",
      "epoch: 192 loss: tensor(0.9138)\n",
      "epoch: 193 loss: tensor(0.9136)\n",
      "epoch: 194 loss: tensor(0.9132)\n",
      "epoch: 195 loss: tensor(0.9133)\n",
      "epoch: 196 loss: tensor(0.9132)\n",
      "epoch: 197 loss: tensor(0.9131)\n",
      "epoch: 198 loss: tensor(0.9129)\n",
      "epoch: 199 loss: tensor(0.9128)\n",
      "epoch: 200 loss: tensor(0.9126)\n"
     ]
    }
   ],
   "source": [
    "# Training our SAE\n",
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0. # Introducing this variable to take only into our computations the users who rated at least one movie\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input) # vector of predicted ratings\n",
    "            target.require_grad = False # Make sure that the gradient is not computed with respect to the target\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_correcter = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward() # Backward is about which weights will be updated, the direction\n",
    "            train_loss += np.sqrt(loss.data[0] * mean_correcter) # getting the state of the art error\n",
    "            s += 1.\n",
    "            optimizer.step() # Optimizer is about the amount by which the weights will be updated\n",
    "     \n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our SAE\n",
    "test_loss = 0\n",
    "s = 0. # number of users who rated at least one movie\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user])\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input) \n",
    "        target.require_grad = False \n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data[0] * mean_corrector) \n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
